# Changelog

## [0.7.2] - 2025-11-04

### ğŸ› Critical Fixes

**generateWithRAG() Improvements:**
- âœ… Added dual API support (new and legacy signatures)
- âœ… Fixed LMStudioRAGClient compatibility
- âœ… Fixed OllamaRAGClient compatibility
- âœ… Smart client detection for proper API usage

**New API (Recommended):**
```javascript
const answer = await generateWithRAG(client, model, query, results);
```

**Legacy API (Still Supported):**
```javascript
const result = await generateWithRAG({ retriever, modelClient, model, query });
```

**What Works Now:**
- âœ… Both Ollama and LM Studio clients work perfectly
- âœ… All README examples tested and working
- âœ… Backward compatibility maintained

---

## [0.7.1] - 2025-11-04

### ğŸ› Bug Fixes

**Critical README Corrections:**
- âœ… Fixed all code examples to use correct API
- âœ… Updated Option 3 (Node.js) to use official SDK
- âœ… Updated Option 4 (LM Studio) with proper usage
- âœ… Corrected API calls:
  - `vectorStore.addDocuments()` (not `retriever.addDocuments()`)
  - `retriever.getRelevant()` (not `retriever.retrieve()`)
  - `LMStudioRAGClient` (not `LMStudioClient`)
  - `createOllamaRAGEmbedding` (recommended over legacy)

**What Changed:**
- All examples now work out-of-the-box
- Consistent API usage throughout documentation
- Clear distinction between official SDK clients and legacy clients

---

## [0.7.0] - 2025-11-04

### ğŸ‰ Major Update: Rebranding + Official SDK Integration

**Package Name Change:**
- ğŸ†• **NEW NAME: `quick-rag`** (was: `js-rag-local-llm`)
- More memorable, cleaner, and easier to use
- npm install: `npm install quick-rag`

**Example Organization:**
- ğŸ“ Cleaned up examples folder (14 â†’ 5 main examples)
- ğŸ“‚ Advanced examples moved to `example/advanced/`
- ğŸ“– New simplified example README

**Breaking Changes:**
- Added official `ollama` (v0.6.2) and `@lmstudio/sdk` (v1.5.0) as dependencies
- New recommended clients: `OllamaRAGClient` and `LMStudioRAGClient`

**New Features:**
- âœ¨ **Full Official SDK Support**: All features from official SDKs now available
  - **Streaming responses** - Real-time token-by-token generation
  - **Tool calling & function execution** - Build autonomous AI agents
  - **Vision model support** - Process images alongside text
  - **Image input handling** - Send images in prompts
  - **Web search & fetch** - Access web content (with Ollama account)
  - **Model management** - list, pull, push, create, delete, copy models
  - **Advanced configuration** - All SDK options exposed

- ğŸ¨ **Dual Client System**:
  - `OllamaRAGClient` - Wraps official `ollama` SDK + RAG features
  - `LMStudioRAGClient` - Wraps official `@lmstudio/sdk` + RAG features
  - Legacy clients still available for backward compatibility

- ğŸ“š **Enhanced Examples**:
  - `official-ollama-example.js` - Showcases official SDK + RAG
  - `lmstudio-example.js` - Complete LM Studio integration

**Backward Compatibility:**
- âœ… All existing code continues to work
- âœ… Legacy clients (`OllamaClient`, `LMStudioClient`) still exported
- âœ… No breaking changes to vector store or retriever APIs
- âœ… Existing examples work as before

**Migration Guide:**
```javascript
// Old way (still works)
import { OllamaClient } from 'js-rag-local-llm';
const client = new OllamaClient();

// New way (recommended - more features!)
import { OllamaRAGClient } from 'js-rag-local-llm';
const client = new OllamaRAGClient();

// Now you get: streaming, tool calling, vision, web search, etc.
```

---

## [0.6.5] - 2025-11-04 (Unreleased)

### ğŸš€ Major Feature: Universal Model Support

- **Auto-fallback to Chat API**: Automatically detects and uses the correct API (generate or chat)
- **Support for ALL Ollama models**: Now works with `llama3.2`, `llama3.1`, `mistral`, `granite4`, `qwen2.5`, and any other Ollama model
- **Seamless experience**: No configuration needed - just use any model name

### âœ¨ New Features

- `OllamaClient.chat()` method for chat-only models
- `_parseResponse()` internal method supporting both API formats
- Automatic warning when falling back to chat API

### ğŸ“ Documentation

- Updated README with universal model support note
- Added `llama-chat-example.js` demonstrating chat-only models
- Removed model restrictions from troubleshooting

### ğŸ”§ Technical

- Response parsing now handles both `response` and `message.content` fields
- Better error handling with helpful messages
- Zero breaking changes - fully backward compatible

---

## [0.6.4] - 2025-11-04

### ğŸ“ Documentation & Examples

- **Clean output examples**: Added `simple-nodejs.js` with beautiful, readable output
- **Better console logging**: Examples now show clean results without vector arrays
- **Improved README**: Added output examples to show expected results
- **Updated example/README.md**: Better organization with new simple example

### ğŸ¨ User Experience

- Output now shows relevance scores as percentages (e.g., "80.2%")
- Clean separation between retrieved docs and AI answers
- No more cluttered vector arrays in console output

---

## [0.6.3] - 2025-11-04

### ğŸ”´ Critical Fix

- **Pure Node.js support**: Fixed React dependency issue in pure Node.js projects
- **Separate entry points**: 
  - Node.js: `src/index.node.js` (no React dependencies)
  - Browser/React: `src/index.js` or `js-rag-local-llm/react`
  - Browser: `src/index.browser.js`

### âœ¨ New Features

- **Automatic response parsing**: `OllamaClient.generate()` now automatically parses NDJSON streaming responses
- **Better package.json exports**: Conditional exports for Node.js vs Browser vs React

### ğŸ“ Documentation

- Added pure Node.js example (`example/pure-nodejs-example.js`)
- Updated README with React import instructions
- Clarified usage for different environments

### ğŸ”§ Technical

- `generate()` method now returns clean text instead of raw NDJSON
- Package correctly resolves entry points based on environment
- No breaking changes for existing users

---

## [0.6.2] - 2025-11-04

### ğŸ“ Documentation

- **Major README overhaul**: Complete rewrite for clarity and user-friendliness
- **Step-by-step guides**: Added detailed setup instructions for React (Vite), Next.js, and vanilla JavaScript
- **Better examples**: Clear, focused code examples for each use case
- **Troubleshooting table**: Quick reference for common issues
- **Cleaner structure**: Organized documentation by framework and use case

### ğŸ¯ Improvements

- Simplified Quick Start section with 6 clear steps
- Added comparison table for different framework setups
- Enhanced API reference with real-world examples
- Better error messages and solutions

---

## [0.6.1] - 2025-11-04

### âœ¨ New Features

- **Single document add**: Added `addDocument(doc, opts)` convenience method to `InMemoryVectorStore` for adding single documents without array wrapping

### ğŸ”§ Improvements

- Simplified API: No need to wrap single documents in arrays anymore
- Better DX: `await store.addDocument({id: 'x', text: '...'})` instead of `await store.addDocuments([{...}])`

### ğŸ“ Documentation

- Updated README with `addDocument()` usage examples
- Added test coverage for single document addition

---

## [0.6.0] - 2025-11-03

### ğŸ”´ Critical Fixes

- **Removed circular dependency**: Package no longer lists itself as a dependency
- **Fixed topK parameter**: `generateWithRAG` now properly passes `topK` to `retriever.getRelevant()`
- **Fixed streaming support**: `generateWithRAG` now returns `prompt` for proper streaming initialization

### âœ¨ New Features

- **VectorStore CRUD operations**: Added `deleteDocument()`, `updateDocument()`, `getDocument()`, `getAllDocuments()`, and `clear()` methods
- **Batch embedding support**: `addDocuments()` now uses `Promise.all()` for parallel embedding (major performance boost)
- **Dynamic topK**: `Retriever.getRelevant()` now accepts optional `topK` parameter to override instance default

### ğŸš€ Improvements

- **Modern fetch usage**: `OllamaClient` now uses native `fetch` (Node.js 18+) with `node-fetch` as fallback
- **Streaming state**: `useRAG` hook now returns `streaming` boolean in addition to `loading`
- **Dependency cleanup**: `node-fetch` moved to `optionalDependencies` (not needed for Node.js 18+)

### ğŸ“ API Changes

- `retriever.getRelevant(query, topK?)` - `topK` is now optional
- `generateWithRAG()` - now returns `{ docs, response, prompt }` (added `prompt`)
- `useRAG()` - now returns `{ run, loading, error, response, docs, streaming }` (added `streaming`)
- `InMemoryVectorStore` - new methods: `deleteDocument()`, `updateDocument()`, `getDocument()`, `getAllDocuments()`, `clear()`

### âš¡ Performance

- Embedding 100 documents is now ~100x faster (parallel vs sequential)
- Reduced bundle size by making `node-fetch` optional

### ğŸ”§ Technical

- All existing tests pass
- No breaking changes for existing users (only additions)
- Better TypeScript inference support (return types are more explicit)

---

## [0.5.0] - Previous Release

- Initial stable release
