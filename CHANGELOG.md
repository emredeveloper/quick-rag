# Changelog

## [1.1.0] - 2025-11-05 âœ¨

### ğŸ¯ Major Feature Release

Two powerful new features that make Quick RAG even more unique!

### âœ¨ New Features

#### ğŸ” Query Explainability
**Industry-first feature!** Now you can see WHY documents were retrieved and understand the retrieval process.

```javascript
const results = await retriever.getRelevant(query, 3, {
  explain: true  // Enable explanations
});

// Each result now includes:
{
  text: "...",
  score: 0.856,
  explanation: {
    queryTerms: ["ollama", "local", "ai"],        // Extracted from query
    matchedTerms: ["ollama", "local"],            // Found in document
    matchCount: 2,                                // Number of matches
    matchRatio: 0.67,                             // Match percentage
    cosineSimilarity: 0.856,                      // Semantic similarity
    relevanceFactors: {
      termMatches: 2,
      semanticSimilarity: 0.856,
      coverage: "67%"
    }
  }
}
```

**Benefits:**
- ğŸ› Debug unexpected search results
- ğŸ“Š Understand semantic vs keyword matching
- âœ… Validate retrieval accuracy
- ğŸ“ˆ Optimize query quality
- ğŸ’¡ Explain results to end users

**No other RAG library offers this level of explainability!**

#### ğŸ¨ Dynamic Prompt Management
Intelligent, flexible prompt system with 10 built-in templates and full customization.

**Built-in Templates:**
- `default` - Standard RAG format
- `conversational` - Chat-style responses
- `technical` - Technical documentation format
- `academic` - Research/scholarly style
- `code` - Code-focused responses
- `concise` - Brief answers
- `detailed` - Comprehensive responses
- `qa` - Question-Answer format
- `instructional` - Step-by-step guides
- `creative` - Creative writing style

**Usage Examples:**

```javascript
// 1. Quick template selection
await generateWithRAG(client, model, query, docs, {
  template: 'conversational'
});

// 2. System prompt for role definition
await generateWithRAG(client, model, query, docs, {
  systemPrompt: 'You are a helpful programming tutor',
  template: 'instructional'
});

// 3. Context formatting options
await generateWithRAG(client, model, query, docs, {
  context: {
    includeScores: true,      // Show similarity scores
    includeMetadata: true,    // Show document metadata
    maxLength: 500           // Limit context length
  }
});

// 4. Advanced: PromptManager for reusable configs
const promptMgr = createPromptManager({
  systemPrompt: 'You are an expert engineer',
  template: 'technical',
  variables: { company: 'TechCorp' }
});

await generateWithRAG(client, model, query, docs, {
  promptManager: promptMgr
});

// 5. Custom template function
const customTemplate = (query, context) => `
  Custom format here
  Query: ${query}
  Context: ${context}
`;

await generateWithRAG(client, model, query, docs, {
  template: customTemplate
});
```

**Benefits:**
- ğŸ­ Different response styles per use case
- ğŸ‘¤ Role-based assistants (tutor, expert, analyst)
- ğŸ¢ Multi-tenant applications with different prompts
- ğŸ§ª A/B test prompt effectiveness
- ğŸ¯ Domain-specific formatting

### ğŸ“ New Files

- `src/promptManager.js` - Complete prompt management system
- `example/08-explain-scores.js` - Query explainability demo (Ollama + LM Studio)
- `example/09-prompt-management.js` - Dynamic prompt system demo

### ğŸ”§ Improvements

- Enhanced `generateWithRAG()` to support options parameter
- Added `explain` option to `retriever.getRelevant()`
- Fixed React import to be optional (no longer requires React dependency)
- Better context formatting in RAG generation
- Improved error messages

### ğŸ“š API Additions

**New Exports:**
```javascript
import {
  PromptManager,          // Advanced prompt management class
  PromptTemplates,        // Built-in template collection
  createPromptManager,    // Factory function
  getTemplate            // Get template by name
} from 'quick-rag';
```

**Enhanced Functions:**
```javascript
// Retriever now supports explain option
retriever.getRelevant(query, topK, { 
  explain: true,
  filters: {...},
  minScore: 0.5 
});

// generateWithRAG now accepts options
generateWithRAG(client, model, query, docs, {
  template: 'conversational',
  systemPrompt: '...',
  promptManager: manager,
  context: {
    includeScores: true,
    includeMetadata: true,
    maxLength: 1000
  }
});
```

### ğŸ¯ Why v1.1.0?

These features represent significant functionality additions that:
1. âœ… Provide unique capabilities not found in competing libraries
2. âœ… Maintain backward compatibility (all v1.0.0 code works unchanged)
3. âœ… Follow semantic versioning (minor version bump for new features)
4. âœ… Are production-ready and fully tested

### ğŸ”„ Migration from v1.0.0

**No breaking changes!** All existing code works as-is. New features are opt-in:

```javascript
// v1.0.0 code - still works!
const results = await retriever.getRelevant(query, 3);
await generateWithRAG(client, model, query, docs);

// v1.1.0 enhancements - optional
const results = await retriever.getRelevant(query, 3, { explain: true });
await generateWithRAG(client, model, query, docs, { template: 'technical' });
```

---

## [1.0.0] - 2025-11-04 ğŸ‰

### ğŸŠ Production Release

**Quick RAG is now production-ready!** This major release marks the stability and maturity of the library with comprehensive features, thorough testing, and excellent developer experience.

### âœ¨ What's Included in v1.0.0

**Core Features:**
- âœ… **Dual Provider Support** - Both Ollama and LM Studio fully tested and working
- âœ… **Document Loaders** - PDF, Word, Excel, Text, JSON, Markdown support
- âœ… **Web Loaders** - Load content from URLs and sitemaps
- âœ… **Smart Chunking** - 4 different chunking strategies
- âœ… **Metadata Filtering** - Filter by any metadata field + minimum score
- âœ… **Streaming Support** - Real-time response streaming
- âœ… **TypeScript Definitions** - Complete type safety
- âœ… **React Hook** - `useRAG` hook for React applications

**Quality Assurance:**
- âœ… **Comprehensive Testing** - All features tested with both providers
- âœ… **Clean Examples** - 10 focused examples (5 for Ollama, 5 for LM Studio)
- âœ… **Error Handling** - Helpful error messages and graceful degradation
- âœ… **Documentation** - Complete API documentation and examples

### ğŸ”§ Breaking Changes from 0.7.x

**None!** This is a stability release. All 0.7.x code will work without changes.

### ğŸ†• New in v1.0.0

**Example Organization:**
- ğŸ“ **Reorganized Examples** - Clear separation between Ollama and LM Studio
- ğŸ“ **Better Documentation** - Each example is self-contained and well-documented
- ğŸ§ª **Test Both Providers** - New dual-provider test script

**Example Files:**
1. `01-basic-usage.js` / `01-basic-usage-lmstudio.js` - Get started
2. `02-document-loading.js` / `02-document-loading-lmstudio.js` - Load PDFs
3. `03-metadata-filtering.js` / `03-metadata-filtering-lmstudio.js` - Filter documents
4. `04-test-both-providers.js` - Test your setup
5. `05-streaming.js` / `05-streaming-lmstudio.js` - Stream responses

**Bug Fixes:**
- âœ… Fixed LM Studio `listLoaded()` API call (was using wrong method)
- âœ… Fixed embedding model caching in LM Studio (no more "model already exists" error)
- âœ… Removed unused imports from example files
- âœ… Cleaned up example directory structure

### ğŸ“¦ Installation

```bash
npm install quick-rag
```

**Optional Dependencies (install as needed):**
```bash
# PDF support
npm install pdf-parse

# Word support
npm install mammoth

# Excel support
npm install xlsx
```

### ğŸš€ Quick Start

**Ollama:**
```javascript
import { 
  OllamaRAGClient, 
  createOllamaRAGEmbedding, 
  InMemoryVectorStore 
} from 'quick-rag';

const client = new OllamaRAGClient();
const embed = createOllamaRAGEmbedding(client, 'embeddinggemma');
const store = new InMemoryVectorStore(embed);

await store.addDocuments([
  { text: 'Your knowledge here' }
]);
```

**LM Studio:**
```javascript
import { 
  LMStudioRAGClient, 
  createLMStudioRAGEmbedding, 
  InMemoryVectorStore 
} from 'quick-rag';

const client = new LMStudioRAGClient();
const embed = createLMStudioRAGEmbedding(client, 'nomic-embed-text-v1.5');
const store = new InMemoryVectorStore(embed);

await store.addDocuments([
  { text: 'Your knowledge here' }
]);
```

### ğŸ“Š Testing

All features thoroughly tested:
- âœ… Ollama integration (embeddinggemma + granite4:tiny-h)
- âœ… LM Studio integration (nomic-embed-text-v1.5 + qwen3-vl-4b)
- âœ… Document loading (PDF, Word, Excel)
- âœ… Web loading (URLs, sitemaps)
- âœ… Chunking strategies (text, sentences, documents, markdown)
- âœ… Metadata filtering
- âœ… Streaming responses
- âœ… Vector store operations
- âœ… RAG pipeline

### ğŸ™ Acknowledgments

Thank you to the community for feedback and testing!

---

## [0.7.4] - 2025-11-04

### ğŸš€ Major Feature: Document Loaders

**Load Various Document Formats:**
- âœ… **PDF Support** - `loadPDF()` (requires: `npm install pdf-parse`)
- âœ… **Word Support** - `loadWord()` for .docx files (requires: `npm install mammoth`)
- âœ… **Excel Support** - `loadExcel()` for .xlsx files (requires: `npm install xlsx`)
- âœ… **Text Files** - `loadText()` for .txt files
- âœ… **JSON Files** - `loadJSON()` with field extraction
- âœ… **Markdown Files** - `loadMarkdown()` with optional syntax stripping
- âœ… **Auto-Detection** - `loadDocument()` automatically detects file type
- âœ… **Directory Loading** - `loadDirectory()` loads entire folders recursively

**Web Content Loading:**
- âœ… `loadURL()` - Load content from any URL
- âœ… `loadURLs()` - Batch load multiple URLs
- âœ… `loadSitemap()` - Extract URLs from sitemap.xml
- âœ… Automatic HTML to text conversion

### ğŸ“¦ New Dependencies

**Optional Dependencies (install only what you need):**
```bash
# PDF support
npm install pdf-parse

# Word support
npm install mammoth

# Excel support
npm install xlsx
```

### ğŸ”§ Usage Examples

**Load PDF and Query:**
```javascript
import { loadPDF, chunkDocuments, InMemoryVectorStore } from 'quick-rag';

// Load PDF
const pdf = await loadPDF('./document.pdf');
console.log(`Loaded ${pdf.meta.pages} pages`);

// Chunk and add to RAG
const chunks = chunkDocuments([pdf], { chunkSize: 500 });
await store.addDocuments(chunks);
```

**Load from URL:**
```javascript
import { loadURL } from 'quick-rag';

const doc = await loadURL('https://example.com', {
  extractText: true  // Convert HTML to plain text
});
```

**Load Entire Directory:**
```javascript
import { loadDirectory } from 'quick-rag';

const docs = await loadDirectory('./documents', {
  extensions: ['.pdf', '.docx', '.txt', '.md'],
  recursive: true
});
console.log(`Loaded ${docs.length} documents`);
```

### ğŸ“š New Examples

- `example/advanced/document-loading-example.js` - Complete guide for document loading

### ğŸ§ª Testing

```bash
npm test
# âœ… Text loader tests passed
# âœ… JSON loader tests passed
# âœ… Markdown loader tests passed
# âœ… Auto-detect tests passed
# âœ… Web loader tests passed
```

### ğŸ“Š What's Supported

| Format | Function | Requires |
|--------|----------|----------|
| PDF | `loadPDF()` | `pdf-parse` |
| Word (.docx) | `loadWord()` | `mammoth` |
| Excel (.xlsx) | `loadExcel()` | `xlsx` |
| Text (.txt) | `loadText()` | Built-in |
| JSON | `loadJSON()` | Built-in |
| Markdown | `loadMarkdown()` | Built-in |
| Web URLs | `loadURL()` | Built-in |

### ğŸ¯ Benefits

- ğŸ“„ **No manual text extraction** - Load documents directly
- ğŸ”„ **Automatic chunking** - Split large documents intelligently
- ğŸ·ï¸ **Metadata preservation** - Keep document metadata through pipeline
- ğŸŒ **Web scraping** - Load content from URLs
- ğŸ“ **Batch processing** - Load entire directories at once
- ğŸ¨ **TypeScript support** - Full type definitions included

---

## [0.7.3] - 2025-11-04

### âœ¨ New Features

**Text Chunking Utilities:**
- âœ… `chunkText()` - Split text by character limit with overlap
- âœ… `chunkBySentences()` - Split by sentences with smart overlap
- âœ… `chunkDocuments()` - Chunk documents with metadata preservation
- âœ… `chunkMarkdown()` - Markdown-aware chunking (preserves code blocks)

**Metadata Filtering:**
- âœ… Filter retrieval results by metadata fields
- âœ… Support for exact match, array contains, and regex patterns
- âœ… Minimum similarity score filtering
- âœ… Multiple filters can be combined

**TypeScript Support:**
- âœ… Full TypeScript definitions (`src/index.d.ts`)
- âœ… Complete type coverage for all exports
- âœ… IntelliSense and autocomplete in VS Code
- âœ… Type-safe API calls

**Enhanced Testing:**
- âœ… Comprehensive chunking tests
- âœ… Metadata filtering tests
- âœ… Integration tests (optional, requires Ollama)
- âœ… Test coverage for all new features

**useRAG Hook Improvements:**
- âœ… Fixed streaming support for OllamaRAGClient
- âœ… Fixed streaming support for LMStudioRAGClient
- âœ… Smart client detection for proper API usage
- âœ… Better error handling

### ğŸ“š Examples

**New Advanced Examples:**
- `example/advanced/chunking-example.js` - Comprehensive chunking guide
- `example/advanced/metadata-filtering-example.js` - Advanced filtering patterns

### ğŸ”§ API Changes

**Retriever.getRelevant()** now accepts options parameter:
```javascript
// Before
const results = await retriever.getRelevant(query, k);

// Now (backward compatible)
const results = await retriever.getRelevant(query, k, {
  filters: { source: 'web', year: 2024 },
  minScore: 0.5
});
```

**New Exports:**
```javascript
import { 
  chunkText, 
  chunkBySentences, 
  chunkDocuments, 
  chunkMarkdown 
} from 'quick-rag';
```

### ğŸ“Š Test Results

```bash
npm test
# âœ… vectorStore tests passed
# âœ… retriever tests passed
# âœ… chunking tests passed (4 test suites)
# âœ… metadata filtering tests passed (2 test suites)
# âœ… ALL TESTS PASSED!
```

---

## [0.7.2] - 2025-11-04

### ğŸ› Critical Fixes

**generateWithRAG() Improvements:**
- âœ… Added dual API support (new and legacy signatures)
- âœ… Fixed LMStudioRAGClient compatibility
- âœ… Fixed OllamaRAGClient compatibility
- âœ… Smart client detection for proper API usage

**New API (Recommended):**
```javascript
const answer = await generateWithRAG(client, model, query, results);
```

**Legacy API (Still Supported):**
```javascript
const result = await generateWithRAG({ retriever, modelClient, model, query });
```

**What Works Now:**
- âœ… Both Ollama and LM Studio clients work perfectly
- âœ… All README examples tested and working
- âœ… Backward compatibility maintained

---

## [0.7.1] - 2025-11-04

### ğŸ› Bug Fixes

**Critical README Corrections:**
- âœ… Fixed all code examples to use correct API
- âœ… Updated Option 3 (Node.js) to use official SDK
- âœ… Updated Option 4 (LM Studio) with proper usage
- âœ… Corrected API calls:
  - `vectorStore.addDocuments()` (not `retriever.addDocuments()`)
  - `retriever.getRelevant()` (not `retriever.retrieve()`)
  - `LMStudioRAGClient` (not `LMStudioClient`)
  - `createOllamaRAGEmbedding` (recommended over legacy)

**What Changed:**
- All examples now work out-of-the-box
- Consistent API usage throughout documentation
- Clear distinction between official SDK clients and legacy clients

---

## [0.7.0] - 2025-11-04

### ğŸ‰ Major Update: Rebranding + Official SDK Integration

**Package Name Change:**
- ğŸ†• **NEW NAME: `quick-rag`** (was: `js-rag-local-llm`)
- More memorable, cleaner, and easier to use
- npm install: `npm install quick-rag`

**Example Organization:**
- ğŸ“ Cleaned up examples folder (14 â†’ 5 main examples)
- ğŸ“‚ Advanced examples moved to `example/advanced/`
- ğŸ“– New simplified example README

**Breaking Changes:**
- Added official `ollama` (v0.6.2) and `@lmstudio/sdk` (v1.5.0) as dependencies
- New recommended clients: `OllamaRAGClient` and `LMStudioRAGClient`

**New Features:**
- âœ¨ **Full Official SDK Support**: All features from official SDKs now available
  - **Streaming responses** - Real-time token-by-token generation
  - **Tool calling & function execution** - Build autonomous AI agents
  - **Vision model support** - Process images alongside text
  - **Image input handling** - Send images in prompts
  - **Web search & fetch** - Access web content (with Ollama account)
  - **Model management** - list, pull, push, create, delete, copy models
  - **Advanced configuration** - All SDK options exposed

- ğŸ¨ **Dual Client System**:
  - `OllamaRAGClient` - Wraps official `ollama` SDK + RAG features
  - `LMStudioRAGClient` - Wraps official `@lmstudio/sdk` + RAG features
  - Legacy clients still available for backward compatibility

- ğŸ“š **Enhanced Examples**:
  - `official-ollama-example.js` - Showcases official SDK + RAG
  - `lmstudio-example.js` - Complete LM Studio integration

**Backward Compatibility:**
- âœ… All existing code continues to work
- âœ… Legacy clients (`OllamaClient`, `LMStudioClient`) still exported
- âœ… No breaking changes to vector store or retriever APIs
- âœ… Existing examples work as before

**Migration Guide:**
```javascript
// Old way (still works)
import { OllamaClient } from 'js-rag-local-llm';
const client = new OllamaClient();

// New way (recommended - more features!)
import { OllamaRAGClient } from 'js-rag-local-llm';
const client = new OllamaRAGClient();

// Now you get: streaming, tool calling, vision, web search, etc.
```

---

## [0.6.5] - 2025-11-04 (Unreleased)

### ğŸš€ Major Feature: Universal Model Support

- **Auto-fallback to Chat API**: Automatically detects and uses the correct API (generate or chat)
- **Support for ALL Ollama models**: Now works with `llama3.2`, `llama3.1`, `mistral`, `granite4`, `qwen2.5`, and any other Ollama model
- **Seamless experience**: No configuration needed - just use any model name

### âœ¨ New Features

- `OllamaClient.chat()` method for chat-only models
- `_parseResponse()` internal method supporting both API formats
- Automatic warning when falling back to chat API

### ğŸ“ Documentation

- Updated README with universal model support note
- Added `llama-chat-example.js` demonstrating chat-only models
- Removed model restrictions from troubleshooting

### ğŸ”§ Technical

- Response parsing now handles both `response` and `message.content` fields
- Better error handling with helpful messages
- Zero breaking changes - fully backward compatible

---

## [0.6.4] - 2025-11-04

### ğŸ“ Documentation & Examples

- **Clean output examples**: Added `simple-nodejs.js` with beautiful, readable output
- **Better console logging**: Examples now show clean results without vector arrays
- **Improved README**: Added output examples to show expected results
- **Updated example/README.md**: Better organization with new simple example

### ğŸ¨ User Experience

- Output now shows relevance scores as percentages (e.g., "80.2%")
- Clean separation between retrieved docs and AI answers
- No more cluttered vector arrays in console output

---

## [0.6.3] - 2025-11-04

### ğŸ”´ Critical Fix

- **Pure Node.js support**: Fixed React dependency issue in pure Node.js projects
- **Separate entry points**: 
  - Node.js: `src/index.node.js` (no React dependencies)
  - Browser/React: `src/index.js` or `js-rag-local-llm/react`
  - Browser: `src/index.browser.js`

### âœ¨ New Features

- **Automatic response parsing**: `OllamaClient.generate()` now automatically parses NDJSON streaming responses
- **Better package.json exports**: Conditional exports for Node.js vs Browser vs React

### ğŸ“ Documentation

- Added pure Node.js example (`example/pure-nodejs-example.js`)
- Updated README with React import instructions
- Clarified usage for different environments

### ğŸ”§ Technical

- `generate()` method now returns clean text instead of raw NDJSON
- Package correctly resolves entry points based on environment
- No breaking changes for existing users

---

## [0.6.2] - 2025-11-04

### ğŸ“ Documentation

- **Major README overhaul**: Complete rewrite for clarity and user-friendliness
- **Step-by-step guides**: Added detailed setup instructions for React (Vite), Next.js, and vanilla JavaScript
- **Better examples**: Clear, focused code examples for each use case
- **Troubleshooting table**: Quick reference for common issues
- **Cleaner structure**: Organized documentation by framework and use case

### ğŸ¯ Improvements

- Simplified Quick Start section with 6 clear steps
- Added comparison table for different framework setups
- Enhanced API reference with real-world examples
- Better error messages and solutions

---

## [0.6.1] - 2025-11-04

### âœ¨ New Features

- **Single document add**: Added `addDocument(doc, opts)` convenience method to `InMemoryVectorStore` for adding single documents without array wrapping

### ğŸ”§ Improvements

- Simplified API: No need to wrap single documents in arrays anymore
- Better DX: `await store.addDocument({id: 'x', text: '...'})` instead of `await store.addDocuments([{...}])`

### ğŸ“ Documentation

- Updated README with `addDocument()` usage examples
- Added test coverage for single document addition

---

## [0.6.0] - 2025-11-03

### ğŸ”´ Critical Fixes

- **Removed circular dependency**: Package no longer lists itself as a dependency
- **Fixed topK parameter**: `generateWithRAG` now properly passes `topK` to `retriever.getRelevant()`
- **Fixed streaming support**: `generateWithRAG` now returns `prompt` for proper streaming initialization

### âœ¨ New Features

- **VectorStore CRUD operations**: Added `deleteDocument()`, `updateDocument()`, `getDocument()`, `getAllDocuments()`, and `clear()` methods
- **Batch embedding support**: `addDocuments()` now uses `Promise.all()` for parallel embedding (major performance boost)
- **Dynamic topK**: `Retriever.getRelevant()` now accepts optional `topK` parameter to override instance default

### ğŸš€ Improvements

- **Modern fetch usage**: `OllamaClient` now uses native `fetch` (Node.js 18+) with `node-fetch` as fallback
- **Streaming state**: `useRAG` hook now returns `streaming` boolean in addition to `loading`
- **Dependency cleanup**: `node-fetch` moved to `optionalDependencies` (not needed for Node.js 18+)

### ğŸ“ API Changes

- `retriever.getRelevant(query, topK?)` - `topK` is now optional
- `generateWithRAG()` - now returns `{ docs, response, prompt }` (added `prompt`)
- `useRAG()` - now returns `{ run, loading, error, response, docs, streaming }` (added `streaming`)
- `InMemoryVectorStore` - new methods: `deleteDocument()`, `updateDocument()`, `getDocument()`, `getAllDocuments()`, `clear()`

### âš¡ Performance

- Embedding 100 documents is now ~100x faster (parallel vs sequential)
- Reduced bundle size by making `node-fetch` optional

### ğŸ”§ Technical

- All existing tests pass
- No breaking changes for existing users (only additions)
- Better TypeScript inference support (return types are more explicit)

---

## [0.5.0] - Previous Release

- Initial stable release
