# ğŸš€ Quick RAG - React Projesi Kurulum Rehberi

Bu rehber, sÄ±fÄ±rdan bir React projesi aÃ§Ä±p Quick RAG kÃ¼tÃ¼phanesini kullanmak isteyenler iÃ§in hazÄ±rlanmÄ±ÅŸtÄ±r.

## ğŸ“‹ Gereksinimler

1. **Node.js 18+** yÃ¼klÃ¼ olmalÄ±
2. **Ollama** kurulu ve Ã§alÄ±ÅŸÄ±yor olmalÄ±
3. **Gerekli modeller** Ã§ekilmiÅŸ olmalÄ±

## ğŸ¯ AdÄ±m AdÄ±m Kurulum

### AdÄ±m 1: React Projesi OluÅŸturun

```bash
npm create vite@latest my-rag-app -- --template react
cd my-rag-app
npm install
```

### AdÄ±m 2: Quick RAG ve BaÄŸÄ±mlÄ±lÄ±klarÄ± YÃ¼kleyin

```bash
npm install quick-rag express concurrently multer
npm install --save-dev concurrently
```

**Not:** `quick-rag` paketi (v2.0.3+) otomatik olarak `ollama` ve `@lmstudio/sdk` paketlerini yÃ¼kler.

### AdÄ±m 3: Ollama'yÄ± Kurun ve Modelleri Ã‡ekin

**Ollama Kurulumu:**
- [ollama.ai](https://ollama.ai) adresinden indirin ve kurun
- Terminal'de kontrol edin: `ollama --version`

**Gerekli Modelleri Ã‡ekin:**
```bash
# LLM modeli (soru-cevap iÃ§in)
ollama pull granite4:3b

# Embedding modeli (dokÃ¼man arama iÃ§in)
ollama pull embeddinggemma:latest
```

**Ollama'nÄ±n Ã‡alÄ±ÅŸtÄ±ÄŸÄ±nÄ± Kontrol Edin:**
```bash
# Ollama servisini baÅŸlatÄ±n (eÄŸer Ã§alÄ±ÅŸmÄ±yorsa)
ollama serve

# Modelleri listeleyin
ollama list
```

### AdÄ±m 4: Backend Proxy Server OluÅŸturun

Proje kÃ¶k dizininde `server.js` dosyasÄ± oluÅŸturun:

```javascript
// server.js
import express from 'express';
import { OllamaRAGClient } from 'quick-rag';
import multer from 'multer';
import fs from 'fs/promises';
import path from 'path';
import { fileURLToPath } from 'url';

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

const app = express();
app.use(express.json({ limit: '50mb' }));
app.use(express.urlencoded({ extended: true, limit: '50mb' }));

// CORS (geliÅŸtirme iÃ§in)
app.use((req, res, next) => {
  res.header('Access-Control-Allow-Origin', '*');
  res.header('Access-Control-Allow-Headers', 'Content-Type');
  next();
});

const upload = multer({ dest: 'uploads/' });

// Ollama client
const client = new OllamaRAGClient({ host: 'http://127.0.0.1:11434' });

// Text generation endpoint
app.post('/api/rag-generate', async (req, res) => {
  try {
    const { model = 'granite4:3b', prompt, stream } = req.body;
    
    if (stream) {
      res.setHeader('Content-Type', 'text/event-stream');
      res.setHeader('Cache-Control', 'no-cache');
      res.setHeader('Connection', 'keep-alive');
      
      const streamResponse = await client.chat({
        model,
        messages: [{ role: 'user', content: prompt }],
        stream: true
      });
      
      for await (const chunk of streamResponse) {
        const content = chunk.message?.content || '';
        if (content) {
          res.write(JSON.stringify({ response: content }) + '\n');
        }
      }
      res.end();
    } else {
      const response = await client.generate({ model, prompt });
      res.json({ response: response.response || response });
    }
  } catch (e) {
    if (!res.headersSent) {
      res.status(500).json({ error: String(e) });
    }
  }
});

// Embedding endpoint
app.post('/api/embed', async (req, res) => {
  try {
    const { model = 'embeddinggemma', input } = req.body;
    const resp = await client.embed(model, input);
    res.json(resp);
  } catch (e) {
    res.status(500).json({ error: String(e) });
  }
});

// File upload endpoint
app.post('/api/upload', upload.single('file'), async (req, res) => {
  try {
    if (!req.file) {
      return res.status(400).json({ error: 'No file uploaded' });
    }

    const { loadDocument } = await import('quick-rag');
    const result = await loadDocument(req.file.path);
    
    // Cleanup
    await fs.unlink(req.file.path).catch(() => {});
    
    res.json({
      success: true,
      text: result.text,
      filename: req.file.originalname,
      meta: result.meta
    });
  } catch (e) {
    res.status(500).json({ error: e.message });
  }
});

// Uploads klasÃ¶rÃ¼nÃ¼ oluÅŸtur
(async () => {
  await fs.mkdir('uploads', { recursive: true }).catch(() => {});
})();

app.listen(3001, () => console.log('ğŸš€ Backend Server: http://127.0.0.1:3001'));
```

### AdÄ±m 5: Vite Proxy YapÄ±landÄ±rmasÄ±

`vite.config.js` dosyasÄ±nÄ± gÃ¼ncelleyin:

```javascript
import { defineConfig } from 'vite';
import react from '@vitejs/plugin-react';

export default defineConfig({
  plugins: [react()],
  server: {
    proxy: {
      '/api': {
        target: 'http://127.0.0.1:3001',
        changeOrigin: true
      }
    }
  },
  optimizeDeps: {
    exclude: ['quick-rag']
  },
  resolve: {
    dedupe: ['react', 'react-dom']
  }
});
```

### AdÄ±m 6: Package.json Scripts GÃ¼ncelleme

`package.json` dosyasÄ±ndaki `scripts` bÃ¶lÃ¼mÃ¼nÃ¼ gÃ¼ncelleyin:

```json
{
  "scripts": {
    "dev": "concurrently \"npm:dev:server\" \"npm:dev:client\"",
    "dev:server": "node server.js",
    "dev:client": "vite",
    "build": "vite build",
    "preview": "vite preview"
  }
}
```

### AdÄ±m 7: React Component'te KullanÄ±m

`src/App.jsx` dosyasÄ±nÄ± gÃ¼ncelleyin:

```jsx
import { useState, useEffect } from 'react';
import { useRAG, initRAG, createBrowserModelClient } from 'quick-rag';

// Ã–rnek dokÃ¼manlar
const docs = [
  { id: '1', text: 'React is a JavaScript library for building user interfaces.' },
  { id: '2', text: 'Ollama provides local LLM hosting capabilities.' },
  { id: '3', text: 'RAG combines retrieval with AI generation.' }
];

export default function App() {
  const [rag, setRAG] = useState(null);
  const [query, setQuery] = useState('');
  const [isReady, setIsReady] = useState(false);
  
  const { run, loading, response, docs: results, error } = useRAG({
    retriever: rag?.retriever,
    modelClient: createBrowserModelClient({ endpoint: '/api/rag-generate' }),
    model: 'granite4:3b'
  });

  // RAG sistemini baÅŸlat
  useEffect(() => {
    initRAG(docs, {
      baseEmbeddingOptions: {
        useBrowser: true,
        baseUrl: '/api/embed',
        model: 'embeddinggemma'
      }
    }).then(core => {
      setRAG(core);
      setIsReady(true);
    }).catch(err => {
      console.error('RAG initialization failed:', err);
    });
  }, []);

  const handleAsk = async () => {
    if (!query.trim() || loading) return;
    await run(query);
  };

  return (
    <div style={{ padding: 40, maxWidth: 800, margin: '0 auto' }}>
      <h1>ğŸ¤– Quick RAG Demo</h1>
      
      {!isReady && (
        <p>â³ RAG sistemi baÅŸlatÄ±lÄ±yor...</p>
      )}
      
      {isReady && (
        <>
          <div style={{ marginBottom: 20 }}>
            <input
              value={query}
              onChange={e => setQuery(e.target.value)}
              onKeyDown={e => e.key === 'Enter' && handleAsk()}
              placeholder="Sorunuzu yazÄ±n..."
              style={{ 
                width: '100%', 
                padding: 12, 
                fontSize: 16,
                borderRadius: 8,
                border: '1px solid #ccc'
              }}
            />
            <button
              onClick={handleAsk}
              disabled={loading || !query.trim()}
              style={{
                marginTop: 10,
                padding: '12px 24px',
                fontSize: 16,
                borderRadius: 8,
                border: 'none',
                background: loading ? '#ccc' : '#007bff',
                color: 'white',
                cursor: loading ? 'not-allowed' : 'pointer'
              }}
            >
              {loading ? 'â³ DÃ¼ÅŸÃ¼nÃ¼yor...' : 'ğŸš€ Sor'}
            </button>
          </div>
          
          {error && (
            <div style={{ 
              padding: 12, 
              background: '#fee', 
              borderRadius: 8,
              marginBottom: 20
            }}>
              âŒ Hata: {String(error)}
            </div>
          )}
          
          {results && results.length > 0 && (
            <div style={{ marginBottom: 20 }}>
              <h3>ğŸ“š Bulunan DokÃ¼manlar ({results.length}):</h3>
              {results.map((doc, i) => (
                <div key={i} style={{ 
                  padding: 10, 
                  marginBottom: 8,
                  background: '#f5f5f5',
                  borderRadius: 6
                }}>
                  <strong>#{i + 1}</strong> (Skor: {(doc.score * 100).toFixed(1)}%)<br/>
                  {doc.text}
                </div>
              ))}
            </div>
          )}
          
          {response && (
            <div style={{ 
              padding: 20, 
              background: '#e8f5e9',
              borderRadius: 8
            }}>
              <h3>âœ¨ Cevap:</h3>
              <p style={{ whiteSpace: 'pre-wrap' }}>{response}</p>
            </div>
          )}
        </>
      )}
    </div>
  );
}
```

### AdÄ±m 8: UygulamayÄ± Ã‡alÄ±ÅŸtÄ±rÄ±n

```bash
npm run dev
```

Bu komut:
- âœ… Backend server'Ä± baÅŸlatÄ±r (`http://127.0.0.1:3001`)
- âœ… Frontend dev server'Ä± baÅŸlatÄ±r (`http://localhost:5173`)

TarayÄ±cÄ±da `http://localhost:5173` adresini aÃ§Ä±n ve kullanmaya baÅŸlayÄ±n! ğŸ‰

## ğŸ”§ Sorun Giderme

### "Cannot find package 'ollama'" HatasÄ±

```bash
# node_modules'Ä± temizleyip yeniden yÃ¼kleyin
rm -rf node_modules package-lock.json
npm install
```

Windows'ta:
```bash
rmdir /s /q node_modules
del package-lock.json
npm install
```

### "Connection refused" HatasÄ±

- Ollama'nÄ±n Ã§alÄ±ÅŸtÄ±ÄŸÄ±ndan emin olun: `ollama serve`
- Modellerin yÃ¼klÃ¼ olduÄŸunu kontrol edin: `ollama list`
- Port 11434'Ã¼n aÃ§Ä±k olduÄŸunu kontrol edin

### Backend Ã‡alÄ±ÅŸmÄ±yor

- Port 3001'in boÅŸ olduÄŸundan emin olun
- `server.js` dosyasÄ±nÄ±n proje kÃ¶k dizininde olduÄŸunu kontrol edin
- Terminal'de hata mesajlarÄ±nÄ± kontrol edin

### Frontend HatalarÄ±

- Vite config'in doÄŸru olduÄŸundan emin olun
- Browser console'da hata mesajlarÄ±nÄ± kontrol edin
- `/api/embed` ve `/api/rag-generate` endpoint'lerinin Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± kontrol edin

## ğŸ“š Daha Fazla Bilgi

- **Tam DokÃ¼mantasyon:** [README.md](../README.md)
- **Ã–rnekler:** [quickstart/](../quickstart/) klasÃ¶rÃ¼
- **API ReferansÄ±:** README.md iÃ§indeki API Reference bÃ¶lÃ¼mÃ¼

## âœ… Kontrol Listesi

Kurulum tamamlandÄ±ÄŸÄ±nda ÅŸunlarÄ± kontrol edin:

- [ ] Node.js 18+ yÃ¼klÃ¼
- [ ] Ollama kurulu ve Ã§alÄ±ÅŸÄ±yor
- [ ] `granite4:3b` modeli Ã§ekilmiÅŸ
- [ ] `embeddinggemma:latest` modeli Ã§ekilmiÅŸ
- [ ] `quick-rag` paketi yÃ¼klÃ¼
- [ ] Backend server Ã§alÄ±ÅŸÄ±yor (port 3001)
- [ ] Frontend dev server Ã§alÄ±ÅŸÄ±yor (port 5173)
- [ ] TarayÄ±cÄ±da uygulama aÃ§Ä±lÄ±yor
- [ ] Soru sorduÄŸunuzda cevap alÄ±yorsunuz

## ğŸ‰ BaÅŸarÄ±lÄ±!

ArtÄ±k Quick RAG kÃ¼tÃ¼phanesini React projenizde kullanabilirsiniz!

**Sonraki AdÄ±mlar:**
- DokÃ¼man yÃ¼kleme Ã¶zelliklerini ekleyin
- Streaming response'larÄ± aktif edin
- Metadata filtering kullanÄ±n
- Decision Engine ile akÄ±llÄ± arama yapÄ±n
- BÃ¼yÃ¼k PDF'ler iÃ§in batch processing kullanÄ±n (v2.0.3+)

## âš¡ Performance Tips (v2.0.3+)

### BÃ¼yÃ¼k DokÃ¼manlar Ä°Ã§in Batch Processing

BÃ¼yÃ¼k PDF'ler yÃ¼klerken batch processing kullanÄ±n:

```javascript
import { chunkDocuments } from 'quick-rag';

// BÃ¼yÃ¼k PDF'i chunk'lara bÃ¶l
const chunks = chunkDocuments([largePDF], { 
  chunkSize: 1000, 
  overlap: 100 
});

// Batch processing ile ekle
await store.addDocuments(chunks, {
  batchSize: 20,        // 20 chunk/batch (ayarlanabilir)
  maxConcurrent: 5,     // Max 5 concurrent request
  onProgress: (current, total) => {
    console.log(`Progress: ${current}/${total} (${Math.round(current/total*100)}%)`);
  }
});
```

### Rate Limiting AyarlarÄ±

- **KÃ¼Ã§Ã¼k dokÃ¼manlar (< 100 chunk)**: `batchSize: 10, maxConcurrent: 5`
- **Orta dokÃ¼manlar (100-1000 chunk)**: `batchSize: 20, maxConcurrent: 5`
- **BÃ¼yÃ¼k dokÃ¼manlar (> 1000 chunk)**: `batchSize: 30, maxConcurrent: 3`

Daha fazla Ã¶rnek iÃ§in `quickstart/` klasÃ¶rÃ¼ne bakÄ±n!

